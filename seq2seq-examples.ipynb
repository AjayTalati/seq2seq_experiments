{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import tensorflow as tf\n",
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data import decode_output_sequences\n",
    "from model import Seq2SeqModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date normalization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building model\n"
     ]
    }
   ],
   "source": [
    "from date_generator import generate_data, SYMBOLS, SYMBOL_TO_IDX, INPUT_SEQ_LEN, OUTPUT_SEQ_LEN\n",
    "\n",
    "session.close()\n",
    "tf.reset_default_graph()\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "hidden_units = 128\n",
    "batch_size = 32\n",
    "num_symbols = len(SYMBOL_TO_IDX)\n",
    "\n",
    "with tf.variable_scope('model', reuse=None):\n",
    "    training_model = Seq2SeqModel(session=session,\n",
    "                                    hidden_units = hidden_units, \n",
    "                                    input_sequence_len = INPUT_SEQ_LEN,\n",
    "                                    output_sequence_len = OUTPUT_SEQ_LEN,\n",
    "                                    num_input_symbols = num_symbols,\n",
    "                                    num_output_symbols = num_symbols,\n",
    "                                    batch_size = batch_size,\n",
    "                                    is_training=True)\n",
    "\n",
    "training_model.init_variables()\n",
    "\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    testing_model = Seq2SeqModel(session=session,\n",
    "                                    hidden_units = hidden_units, \n",
    "                                    input_sequence_len = INPUT_SEQ_LEN,\n",
    "                                    output_sequence_len = OUTPUT_SEQ_LEN,\n",
    "                                    num_input_symbols = num_symbols,\n",
    "                                    num_output_symbols = num_symbols,\n",
    "                                    batch_size = batch_size,\n",
    "                                    is_training=False)\n",
    "\n",
    "print(\"Finished building model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some data to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Input', 'Target'),\n",
      " ('____1102 ,21 tsuguaG', '2011-08-12___'),\n",
      " ('__91 ,rebmeced 1102G', '2011-12-19___'),\n",
      " ('___________82-01-21G', '2028-10-12___'),\n",
      " ('___________17-21-72G', '1971-12-27___'),\n",
      " ('_____2002 ,90 lirpaG', '2002-04-09___'),\n",
      " ('___1991 ,31 rebotcoG', '1991-10-13___'),\n",
      " ('___________13-70-07G', '1970-07-31___'),\n",
      " ('_________10-60-2202G', '2022-06-01___'),\n",
      " ('_70 ,rebmetpes 3591G', '1953-09-07___'),\n",
      " ('___________32-20-04G', '2040-02-23___')]\n"
     ]
    }
   ],
   "source": [
    "from date_generator import generate_data, SYMBOLS, SYMBOL_TO_IDX, INPUT_SEQ_LEN, OUTPUT_SEQ_LEN \n",
    "\n",
    "date_generator = generate_data(batch_size=10, random_format=False)\n",
    "x, y = next(date_generator)\n",
    "\n",
    "input_strings = decode_output_sequences(x, symbols=SYMBOLS)\n",
    "target_strings = decode_output_sequences(y, symbols=SYMBOLS)\n",
    "\n",
    "pprint([(\"Input\", \"Target\")] + \n",
    "       list(zip(input_strings, target_strings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/64 (epoch 0), train_loss = 0.151, time/batch = 0.092\n",
      "63/64 (epoch 1), train_loss = 0.157, time/batch = 0.081\n",
      "63/64 (epoch 2), train_loss = 0.189, time/batch = 0.067\n",
      "63/64 (epoch 3), train_loss = 0.132, time/batch = 0.107\n",
      "63/64 (epoch 4), train_loss = 0.137, time/batch = 0.068\n",
      "63/64 (epoch 5), train_loss = 0.113, time/batch = 0.062\n",
      "63/64 (epoch 6), train_loss = 0.145, time/batch = 0.067\n",
      "63/64 (epoch 7), train_loss = 0.131, time/batch = 0.105\n",
      "63/64 (epoch 8), train_loss = 0.124, time/batch = 0.077\n",
      "63/64 (epoch 9), train_loss = 0.092, time/batch = 0.066\n",
      "63/64 (epoch 10), train_loss = 0.098, time/batch = 0.068\n",
      "63/64 (epoch 11), train_loss = 0.126, time/batch = 0.068\n",
      "63/64 (epoch 12), train_loss = 0.107, time/batch = 0.099\n",
      "63/64 (epoch 13), train_loss = 0.099, time/batch = 0.071\n",
      "63/64 (epoch 14), train_loss = 0.120, time/batch = 0.066\n",
      "63/64 (epoch 15), train_loss = 0.093, time/batch = 0.067\n",
      "63/64 (epoch 16), train_loss = 0.093, time/batch = 0.064\n",
      "63/64 (epoch 17), train_loss = 0.079, time/batch = 0.073\n",
      "63/64 (epoch 18), train_loss = 0.075, time/batch = 0.093\n",
      "63/64 (epoch 19), train_loss = 0.072, time/batch = 0.066\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "date_generator = generate_data(batch_size=32)\n",
    "training_model.fit(date_generator, num_epochs=20, batches_per_epoch=64)\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[('Input', 'Target', 'Output'),\n",
      " ('_________51/40/9991G', '1999-04-15___', '1999-04-15____'),\n",
      " ('_________11/01/3791G', '1973-10-11___', '1973-11-01____'),\n",
      " ('_______0591 ,60 yamG', '1950-05-06___', '1950-05-06____'),\n",
      " ('__________09 21 rpaG', '1990-04-12___', '2009-04-19____'),\n",
      " ('__________24 32 nujG', '2042-06-23___', '2024-06-23____'),\n",
      " ('___________82-50-15G', '1951-05-28___', '1951-05-28____'),\n",
      " ('__3591 ,32 yraurbefG', '1953-02-23___', '1953-02-23____'),\n",
      " ('_________02-80-7891G', '1987-08-20___', '1987-08-20____'),\n",
      " ('___________63-20-60G', '2036-02-06___', '2036-02-06____'),\n",
      " ('_______3691 ,50 yamG', '1963-05-05___', '1963-05-05____'),\n",
      " ('___________91-50-86G', '1968-05-19___', '1968-05-19____'),\n",
      " ('__________25 52 guaG', '1952-08-25___', '2025-08-25____'),\n",
      " ('___________48-40-62G', '1984-04-26___', '1984-04-26____'),\n",
      " ('___________04-40-31G', '2040-04-13___', '2040-04-13____'),\n",
      " ('___7791 ,10 yraunajG', '1977-01-01___', '1977-01-01____'),\n",
      " ('__________80 92 guaG', '2008-08-29___', '2008-08-29____'),\n",
      " ('_________03-01-9791G', '1979-10-30___', '1979-10-30____'),\n",
      " ('___________42-40-55G', '1955-04-24___', '1954-04-25____'),\n",
      " ('_________92-80-0502G', '2050-08-29___', '2050-08-29____'),\n",
      " ('_________02-90-6591G', '1956-09-20___', '1956-09-20____')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "batch_size = 20\n",
    "date_generator = generate_data(batch_size=batch_size, random_format=False)\n",
    "\n",
    "x, y = next(date_generator)\n",
    "input_strings = decode_output_sequences(x, symbols=SYMBOLS)\n",
    "target_strings = decode_output_sequences(y, symbols=SYMBOLS)\n",
    "\n",
    "model_output = testing_model.predict(x)\n",
    "pred_strings = decode_output_sequences(model_output, symbols=SYMBOLS)\n",
    "\n",
    "pprint([(\"Input\", \"Target\", \"Output\")] + \n",
    "       list(zip(input_strings, target_strings, pred_strings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addition model\n",
    "\n",
    "Train the model to add two numbers, x+y, and output the sum.\n",
    "\n",
    "Generate some example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inputs: ['________92+4G', '________73+0G', '_________9+6G']\n",
      "Targets: ['96_____', '73_____', '15_____']\n"
     ]
    }
   ],
   "source": [
    "from addition_generator import AdditionGenerator, SYMBOLS, SYMBOL_TO_IDX, INPUT_SEQ_LEN, OUTPUT_SEQ_LEN \n",
    "\n",
    "addition_generator = AdditionGenerator(batch_size=3)\n",
    "x, y = addition_generator.next_batch()\n",
    "\n",
    "input_strings = decode_output_sequences(x, symbols=SYMBOLS)\n",
    "target_strings = decode_output_sequences(y, symbols=SYMBOLS)\n",
    "\n",
    "print(\" Inputs:\", input_strings)\n",
    "print(\"Targets:\", target_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building model\n"
     ]
    }
   ],
   "source": [
    "session.close()\n",
    "tf.reset_default_graph()\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "hidden_units = 128\n",
    "num_layers = 2\n",
    "training_batch_size = 32\n",
    "num_symbols = len(SYMBOL_TO_IDX)\n",
    "\n",
    "with tf.variable_scope('model', reuse=None):\n",
    "    training_model = Seq2SeqModel(session=session,\n",
    "                                    hidden_units=hidden_units, \n",
    "                                    num_layers=num_layers,\n",
    "                                    input_sequence_len = INPUT_SEQ_LEN,\n",
    "                                    output_sequence_len = OUTPUT_SEQ_LEN,\n",
    "                                    num_input_symbols = num_symbols,\n",
    "                                    num_output_symbols = num_symbols,\n",
    "                                    batch_size=training_batch_size,\n",
    "                                    is_training=True)\n",
    "\n",
    "training_model.init_variables()\n",
    "\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    testing_model = Seq2SeqModel(session=session,\n",
    "                                    hidden_units = hidden_units, \n",
    "                                    num_layers=num_layers,\n",
    "                                    input_sequence_len = INPUT_SEQ_LEN,\n",
    "                                    output_sequence_len = OUTPUT_SEQ_LEN,\n",
    "                                    num_input_symbols = num_symbols,\n",
    "                                    num_output_symbols = num_symbols,\n",
    "                                    batch_size=training_batch_size,\n",
    "                                    is_training=False)\n",
    "\n",
    "addition_generator = AdditionGenerator(batch_size=training_batch_size)\n",
    "\n",
    "print(\"Finished building model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss = 0.012, val_loss = 0.111, time/epoch = 1.580\n",
      "Epoch 1: train_loss = 0.047, val_loss = 0.142, time/epoch = 1.965\n",
      "Epoch 2: train_loss = 0.024, val_loss = 0.099, time/epoch = 1.821\n",
      "Epoch 3: train_loss = 0.018, val_loss = 0.092, time/epoch = 1.784\n",
      "Epoch 4: train_loss = 0.016, val_loss = 0.090, time/epoch = 1.783\n",
      "Epoch 5: train_loss = 0.024, val_loss = 0.076, time/epoch = 1.648\n",
      "Epoch 6: train_loss = 0.015, val_loss = 0.074, time/epoch = 1.716\n",
      "Epoch 7: train_loss = 0.031, val_loss = 0.048, time/epoch = 1.725\n",
      "Increasing difficulty\n",
      "Epoch 8: train_loss = 0.627, val_loss = 0.806, time/epoch = 1.739\n",
      "Epoch 9: train_loss = 0.523, val_loss = 0.699, time/epoch = 1.749\n",
      "Epoch 10: train_loss = 0.459, val_loss = 0.634, time/epoch = 1.821\n",
      "Epoch 11: train_loss = 0.378, val_loss = 0.595, time/epoch = 1.814\n",
      "Epoch 12: train_loss = 0.434, val_loss = 0.587, time/epoch = 1.980\n",
      "Epoch 13: train_loss = 0.315, val_loss = 0.569, time/epoch = 1.734\n",
      "Epoch 14: train_loss = 0.364, val_loss = 0.583, time/epoch = 1.824\n",
      "Epoch 15: train_loss = 0.400, val_loss = 0.538, time/epoch = 1.651\n",
      "Epoch 16: train_loss = 0.208, val_loss = 0.512, time/epoch = 1.796\n",
      "Epoch 17: train_loss = 0.327, val_loss = 0.489, time/epoch = 1.898\n",
      "Epoch 18: train_loss = 0.312, val_loss = 0.482, time/epoch = 1.681\n",
      "Epoch 19: train_loss = 0.223, val_loss = 0.458, time/epoch = 1.577\n",
      "Epoch 20: train_loss = 0.208, val_loss = 0.452, time/epoch = 1.816\n",
      "Epoch 21: train_loss = 0.253, val_loss = 0.433, time/epoch = 1.653\n",
      "Epoch 22: train_loss = 0.187, val_loss = 0.430, time/epoch = 2.010\n",
      "Epoch 23: train_loss = 0.234, val_loss = 0.413, time/epoch = 1.767\n",
      "Epoch 24: train_loss = 0.142, val_loss = 0.425, time/epoch = 1.796\n",
      "Epoch 25: train_loss = 0.199, val_loss = 0.435, time/epoch = 1.718\n",
      "Epoch 26: train_loss = 0.140, val_loss = 0.404, time/epoch = 1.572\n",
      "Epoch 27: train_loss = 0.187, val_loss = 0.390, time/epoch = 1.567\n",
      "Epoch 28: train_loss = 0.314, val_loss = 0.404, time/epoch = 1.943\n",
      "Epoch 29: train_loss = 0.187, val_loss = 0.365, time/epoch = 1.872\n",
      "Epoch 30: train_loss = 0.145, val_loss = 0.359, time/epoch = 1.602\n",
      "Epoch 31: train_loss = 0.194, val_loss = 0.340, time/epoch = 1.885\n",
      "Epoch 32: train_loss = 0.261, val_loss = 0.319, time/epoch = 1.985\n",
      "Epoch 33: train_loss = 0.262, val_loss = 0.344, time/epoch = 1.910\n",
      "Epoch 34: train_loss = 0.234, val_loss = 0.318, time/epoch = 1.862\n",
      "Epoch 35: train_loss = 0.166, val_loss = 0.333, time/epoch = 1.772\n",
      "Epoch 36: train_loss = 0.169, val_loss = 0.323, time/epoch = 1.619\n",
      "Epoch 37: train_loss = 0.130, val_loss = 0.330, time/epoch = 1.675\n",
      "Epoch 38: train_loss = 0.130, val_loss = 0.334, time/epoch = 1.542\n",
      "Epoch 39: train_loss = 0.094, val_loss = 0.318, time/epoch = 1.919\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "training_model.fit_curr(addition_generator, testing_model=testing_model, num_epochs=40, batches_per_epoch=20)\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 0.4\n",
      "[('Input', 'Target', 'Output'),\n",
      " ('_____631+962G', '1593___', '1663____'),\n",
      " ('________0+10G', '10_____', '10______'),\n",
      " ('________0+80G', '80_____', '80______'),\n",
      " ('______142+10G', '152____', '152_____'),\n",
      " ('_______271+1G', '272____', '282_____'),\n",
      " ('________4+38G', '42_____', '42______'),\n",
      " ('______824+10G', '834____', '824_____'),\n",
      " ('_____843+365G', '1208___', '1228____'),\n",
      " ('________18+1G', '19_____', '19______'),\n",
      " ('_______16+28G', '44_____', '44______')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "batch_size = 10\n",
    "test_generator = AdditionGenerator(batch_size=batch_size, number_len=3)\n",
    "\n",
    "x, y = test_generator.next_batch()\n",
    "input_strings = decode_output_sequences(x, symbols=SYMBOLS)\n",
    "target_strings = decode_output_sequences(y, symbols=SYMBOLS)\n",
    "\n",
    "model_output = testing_model.predict(x)\n",
    "pred_strings = decode_output_sequences(model_output, symbols=SYMBOLS)\n",
    "\n",
    "print(\"Error rate:\", testing_model.validate([(x, y)]))\n",
    "\n",
    "pprint([(\"Input\", \"Target\", \"Output\")] + \n",
    "       list(zip(input_strings, target_strings, pred_strings)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program execution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inputs: ['________________________________________________________________________a=3\\nif a>9:\\n  a+=3\\nprint(a)G', '_____________________________________________________________________h=17\\nif h>85:\\n  h=h-1\\nprint(h)G', '________________________________________________________________________________h=25\\nd=1\\nprint(h+d)G', '_________________________________________________________________________________d=9\\nd-=11\\nprint(d)G', '_______________________________________________________________________________f=72\\nd=48\\nprint(f+d)G', '________________________________________________________________________________e=70\\ne=e-3\\nprint(e)G', '________________________________________________________________________________d=1\\nd=d+93\\nprint(d)G', '_________________________________________________________________________________h=0\\nf=7\\nprint(h-f)G', '________________________________________________________________________________b=5\\nh=24\\nprint(h+b)G', '________________________________________________________________________________f=20\\nd=5\\nprint(f+d)G']\n",
      "Targets: ['3_________', '17________', '26________', '-2________', '120_______', '67________', '94________', '-7________', '29________', '25________']\n"
     ]
    }
   ],
   "source": [
    "from program_generator import ProgramGenerator, SYMBOLS, SYMBOL_TO_IDX, INPUT_SEQ_LEN, OUTPUT_SEQ_LEN \n",
    "\n",
    "program_generator = ProgramGenerator(batch_size=10, program_length=1, num_len=2)\n",
    "x, y = program_generator.next_batch()\n",
    "\n",
    "input_strings = decode_output_sequences(x, symbols=SYMBOLS)\n",
    "target_strings = decode_output_sequences(y, symbols=SYMBOLS)\n",
    "\n",
    "print(\" Inputs:\", input_strings)\n",
    "print(\"Targets:\", target_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building model\n"
     ]
    }
   ],
   "source": [
    "session.close()\n",
    "tf.reset_default_graph()\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "hidden_units = 160\n",
    "num_layers = 2\n",
    "training_batch_size = 32\n",
    "num_symbols = len(SYMBOL_TO_IDX)\n",
    "\n",
    "with tf.variable_scope('model', reuse=None):\n",
    "    training_model = Seq2SeqModel(session=session,\n",
    "                                    hidden_units=hidden_units, \n",
    "                                    num_layers=num_layers,\n",
    "                                    input_sequence_len = INPUT_SEQ_LEN,\n",
    "                                    output_sequence_len = OUTPUT_SEQ_LEN,\n",
    "                                    num_input_symbols = num_symbols,\n",
    "                                    num_output_symbols = num_symbols,\n",
    "                                    batch_size=training_batch_size,\n",
    "                                    is_training=True)\n",
    "\n",
    "training_model.init_variables()\n",
    "\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    testing_model = Seq2SeqModel(session=session,\n",
    "                                    hidden_units = hidden_units, \n",
    "                                    num_layers=num_layers,\n",
    "                                    input_sequence_len = INPUT_SEQ_LEN,\n",
    "                                    output_sequence_len = OUTPUT_SEQ_LEN,\n",
    "                                    num_input_symbols = num_symbols,\n",
    "                                    num_output_symbols = num_symbols,\n",
    "                                    batch_size=training_batch_size,\n",
    "                                    is_training=False)\n",
    "\n",
    "program_generator = ProgramGenerator(batch_size=training_batch_size, program_length=1, num_len=2)\n",
    "\n",
    "print(\"Finished building model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss = 0.536, val_error_rate = 0.994, time/epoch = 84.344\n",
      "Epoch 1: train_loss = 0.517, val_error_rate = 0.990, time/epoch = 77.085\n",
      "Epoch 2: train_loss = 0.540, val_error_rate = 0.974, time/epoch = 77.576\n",
      "Epoch 3: train_loss = 0.530, val_error_rate = 0.989, time/epoch = 74.290\n",
      "Epoch 4: train_loss = 0.498, val_error_rate = 0.971, time/epoch = 76.031\n",
      "Epoch 5: train_loss = 0.487, val_error_rate = 0.970, time/epoch = 74.731\n",
      "Epoch 6: train_loss = 0.474, val_error_rate = 0.967, time/epoch = 74.710\n",
      "Epoch 7: train_loss = 0.451, val_error_rate = 0.970, time/epoch = 76.828\n",
      "Epoch 8: train_loss = 0.422, val_error_rate = 0.968, time/epoch = 81.042\n",
      "Epoch 9: train_loss = 0.403, val_error_rate = 0.950, time/epoch = 77.604\n",
      "Epoch 10: train_loss = 0.370, val_error_rate = 0.943, time/epoch = 81.424\n",
      "Epoch 11: train_loss = 0.338, val_error_rate = 0.937, time/epoch = 78.480\n",
      "Epoch 12: train_loss = 0.322, val_error_rate = 0.906, time/epoch = 78.038\n",
      "Epoch 13: train_loss = 0.323, val_error_rate = 0.900, time/epoch = 75.192\n",
      "Epoch 14: train_loss = 0.285, val_error_rate = 0.887, time/epoch = 82.348\n",
      "Epoch 15: train_loss = 0.283, val_error_rate = 0.862, time/epoch = 84.617\n",
      "Epoch 16: train_loss = 0.296, val_error_rate = 0.829, time/epoch = 77.695\n",
      "Epoch 17: train_loss = 0.292, val_error_rate = 0.844, time/epoch = 78.220\n",
      "Epoch 18: train_loss = 0.264, val_error_rate = 0.760, time/epoch = 79.331\n",
      "Epoch 19: train_loss = 0.280, val_error_rate = 0.771, time/epoch = 76.621\n",
      "Epoch 20: train_loss = 0.202, val_error_rate = 0.739, time/epoch = 74.106\n",
      "Epoch 21: train_loss = 0.213, val_error_rate = 0.723, time/epoch = 75.381\n",
      "Epoch 22: train_loss = 0.293, val_error_rate = 0.739, time/epoch = 72.793\n",
      "Epoch 23: train_loss = 0.214, val_error_rate = 0.707, time/epoch = 77.820\n",
      "Epoch 24: train_loss = 0.176, val_error_rate = 0.656, time/epoch = 73.308\n",
      "Epoch 25: train_loss = 0.202, val_error_rate = 0.669, time/epoch = 76.918\n",
      "Epoch 26: train_loss = 0.181, val_error_rate = 0.632, time/epoch = 75.731\n",
      "Epoch 27: train_loss = 0.158, val_error_rate = 0.618, time/epoch = 78.400\n",
      "Epoch 28: train_loss = 0.135, val_error_rate = 0.623, time/epoch = 86.235\n",
      "Epoch 29: train_loss = 0.238, val_error_rate = 0.752, time/epoch = 74.007\n",
      "Epoch 30: train_loss = 0.205, val_error_rate = 0.642, time/epoch = 80.437\n",
      "Epoch 31: train_loss = 0.209, val_error_rate = 0.600, time/epoch = 75.828\n",
      "Epoch 32: train_loss = 0.185, val_error_rate = 0.621, time/epoch = 79.132\n",
      "Epoch 33: train_loss = 0.178, val_error_rate = 0.593, time/epoch = 76.867\n",
      "Epoch 34: train_loss = 0.149, val_error_rate = 0.596, time/epoch = 78.126\n",
      "Epoch 35: train_loss = 0.165, val_error_rate = 0.591, time/epoch = 78.863\n",
      "Epoch 36: train_loss = 0.230, val_error_rate = 0.578, time/epoch = 76.896\n",
      "Epoch 37: train_loss = 0.119, val_error_rate = 0.595, time/epoch = 75.760\n",
      "Epoch 38: train_loss = 0.159, val_error_rate = 0.570, time/epoch = 81.626\n",
      "Epoch 39: train_loss = 0.217, val_error_rate = 0.519, time/epoch = 93.981\n",
      "Epoch 40: train_loss = 0.135, val_error_rate = 0.531, time/epoch = 86.961\n",
      "Epoch 41: train_loss = 0.194, val_error_rate = 0.518, time/epoch = 93.174\n",
      "Epoch 42: train_loss = 0.129, val_error_rate = 0.502, time/epoch = 82.285\n",
      "Epoch 43: train_loss = 0.134, val_error_rate = 0.492, time/epoch = 88.535\n",
      "Epoch 44: train_loss = 0.143, val_error_rate = 0.519, time/epoch = 94.108\n",
      "Epoch 45: train_loss = 0.123, val_error_rate = 0.497, time/epoch = 124.316\n",
      "Epoch 46: train_loss = 0.133, val_error_rate = 0.534, time/epoch = 96.493\n",
      "Epoch 47: train_loss = 0.182, val_error_rate = 0.448, time/epoch = 77.427\n",
      "Epoch 48: train_loss = 0.099, val_error_rate = 0.467, time/epoch = 75.411\n",
      "Epoch 49: train_loss = 0.118, val_error_rate = 0.507, time/epoch = 74.334\n",
      "Epoch 50: train_loss = 0.134, val_error_rate = 0.441, time/epoch = 75.388\n",
      "Epoch 51: train_loss = 0.183, val_error_rate = 0.479, time/epoch = 76.394\n",
      "Epoch 52: train_loss = 0.135, val_error_rate = 0.459, time/epoch = 75.001\n",
      "Epoch 53: train_loss = 0.105, val_error_rate = 0.408, time/epoch = 75.959\n",
      "Epoch 54: train_loss = 0.115, val_error_rate = 0.431, time/epoch = 74.883\n",
      "Epoch 55: train_loss = 0.135, val_error_rate = 0.459, time/epoch = 76.346\n",
      "Epoch 56: train_loss = 0.111, val_error_rate = 0.405, time/epoch = 76.428\n",
      "Epoch 57: train_loss = 0.109, val_error_rate = 0.422, time/epoch = 75.207\n",
      "Epoch 58: train_loss = 0.103, val_error_rate = 0.395, time/epoch = 74.220\n",
      "Epoch 59: train_loss = 0.113, val_error_rate = 0.416, time/epoch = 75.966\n",
      "Epoch 60: train_loss = 0.127, val_error_rate = 0.400, time/epoch = 75.165\n",
      "Epoch 61: train_loss = 0.077, val_error_rate = 0.405, time/epoch = 76.125\n",
      "Epoch 62: train_loss = 0.171, val_error_rate = 0.412, time/epoch = 74.576\n",
      "Epoch 63: train_loss = 0.101, val_error_rate = 0.387, time/epoch = 75.292\n",
      "Epoch 64: train_loss = 0.150, val_error_rate = 0.386, time/epoch = 73.821\n",
      "Epoch 65: train_loss = 0.105, val_error_rate = 0.383, time/epoch = 74.706\n",
      "Epoch 66: train_loss = 0.129, val_error_rate = 0.366, time/epoch = 75.328\n",
      "Epoch 67: train_loss = 0.116, val_error_rate = 0.362, time/epoch = 75.434\n",
      "Epoch 68: train_loss = 0.100, val_error_rate = 0.354, time/epoch = 75.495\n",
      "Epoch 69: train_loss = 0.091, val_error_rate = 0.353, time/epoch = 75.046\n",
      "Epoch 70: train_loss = 0.061, val_error_rate = 0.343, time/epoch = 76.545\n",
      "Epoch 71: train_loss = 0.112, val_error_rate = 0.337, time/epoch = 74.698\n",
      "Epoch 72: train_loss = 0.096, val_error_rate = 0.327, time/epoch = 74.864\n",
      "Epoch 73: train_loss = 0.112, val_error_rate = 0.361, time/epoch = 75.843\n",
      "Epoch 74: train_loss = 0.090, val_error_rate = 0.331, time/epoch = 75.540\n",
      "Epoch 75: train_loss = 0.077, val_error_rate = 0.344, time/epoch = 73.776\n",
      "Epoch 76: train_loss = 0.098, val_error_rate = 0.347, time/epoch = 75.684\n",
      "Epoch 77: train_loss = 0.066, val_error_rate = 0.323, time/epoch = 76.302\n",
      "Epoch 78: train_loss = 0.078, val_error_rate = 0.362, time/epoch = 75.418\n",
      "Epoch 79: train_loss = 0.109, val_error_rate = 0.323, time/epoch = 75.623\n",
      "Epoch 80: train_loss = 0.081, val_error_rate = 0.333, time/epoch = 75.397\n",
      "Epoch 81: train_loss = 0.044, val_error_rate = 0.304, time/epoch = 74.532\n",
      "Epoch 82: train_loss = 0.098, val_error_rate = 0.272, time/epoch = 75.311\n",
      "Epoch 83: train_loss = 0.118, val_error_rate = 0.319, time/epoch = 74.516\n",
      "Epoch 84: train_loss = 0.075, val_error_rate = 0.290, time/epoch = 76.061\n",
      "Epoch 85: train_loss = 0.078, val_error_rate = 0.286, time/epoch = 77.284\n",
      "Epoch 86: train_loss = 0.067, val_error_rate = 0.272, time/epoch = 74.302\n",
      "Epoch 87: train_loss = 0.078, val_error_rate = 0.275, time/epoch = 75.155\n",
      "Epoch 88: train_loss = 0.088, val_error_rate = 0.269, time/epoch = 75.864\n",
      "Epoch 89: train_loss = 0.072, val_error_rate = 0.328, time/epoch = 75.977\n",
      "Epoch 90: train_loss = 0.121, val_error_rate = 0.258, time/epoch = 76.501\n",
      "Epoch 91: train_loss = 0.210, val_error_rate = 0.278, time/epoch = 76.698\n",
      "Epoch 92: train_loss = 0.072, val_error_rate = 0.259, time/epoch = 75.484\n",
      "Epoch 93: train_loss = 0.037, val_error_rate = 0.245, time/epoch = 74.300\n",
      "Epoch 94: train_loss = 0.053, val_error_rate = 0.234, time/epoch = 75.267\n",
      "Epoch 95: train_loss = 0.058, val_error_rate = 0.269, time/epoch = 73.867\n",
      "Epoch 96: train_loss = 0.057, val_error_rate = 0.272, time/epoch = 75.040\n",
      "Epoch 97: train_loss = 0.072, val_error_rate = 0.236, time/epoch = 75.436\n",
      "Epoch 98: train_loss = 0.082, val_error_rate = 0.205, time/epoch = 76.730\n",
      "Epoch 99: train_loss = 0.078, val_error_rate = 0.235, time/epoch = 74.586\n",
      "Epoch 100: train_loss = 0.064, val_error_rate = 0.214, time/epoch = 74.665\n",
      "Epoch 101: train_loss = 0.030, val_error_rate = 0.210, time/epoch = 76.219\n",
      "Epoch 102: train_loss = 0.029, val_error_rate = 0.190, time/epoch = 73.911\n",
      "Epoch 103: train_loss = 0.044, val_error_rate = 0.241, time/epoch = 74.240\n",
      "Epoch 104: train_loss = 0.082, val_error_rate = 0.251, time/epoch = 76.451\n",
      "Epoch 105: train_loss = 0.053, val_error_rate = 0.199, time/epoch = 75.568\n",
      "Epoch 106: train_loss = 0.028, val_error_rate = 0.203, time/epoch = 75.041\n",
      "Epoch 107: train_loss = 0.035, val_error_rate = 0.181, time/epoch = 75.812\n",
      "Epoch 108: train_loss = 0.103, val_error_rate = 0.228, time/epoch = 76.948\n",
      "Epoch 109: train_loss = 0.033, val_error_rate = 0.196, time/epoch = 75.397\n",
      "Epoch 110: train_loss = 0.027, val_error_rate = 0.197, time/epoch = 74.846\n",
      "Epoch 111: train_loss = 0.049, val_error_rate = 0.186, time/epoch = 75.278\n",
      "Epoch 112: train_loss = 0.044, val_error_rate = 0.200, time/epoch = 74.638\n",
      "Epoch 113: train_loss = 0.041, val_error_rate = 0.194, time/epoch = 75.347\n",
      "Epoch 114: train_loss = 0.029, val_error_rate = 0.188, time/epoch = 74.904\n",
      "Epoch 115: train_loss = 0.056, val_error_rate = 0.208, time/epoch = 74.934\n",
      "Epoch 116: train_loss = 0.036, val_error_rate = 0.207, time/epoch = 75.941\n",
      "Epoch 117: train_loss = 0.033, val_error_rate = 0.169, time/epoch = 75.589\n",
      "Epoch 118: train_loss = 0.064, val_error_rate = 0.199, time/epoch = 73.828\n",
      "Epoch 119: train_loss = 0.022, val_error_rate = 0.182, time/epoch = 75.861\n",
      "Epoch 120: train_loss = 0.027, val_error_rate = 0.183, time/epoch = 76.146\n",
      "Epoch 121: train_loss = 0.037, val_error_rate = 0.193, time/epoch = 75.545\n",
      "Epoch 122: train_loss = 0.051, val_error_rate = 0.203, time/epoch = 76.964\n",
      "Epoch 123: train_loss = 0.073, val_error_rate = 0.189, time/epoch = 76.266\n",
      "Epoch 124: train_loss = 0.057, val_error_rate = 0.187, time/epoch = 76.100\n",
      "Epoch 125: train_loss = 0.083, val_error_rate = 0.181, time/epoch = 74.643\n",
      "Epoch 126: train_loss = 0.054, val_error_rate = 0.162, time/epoch = 76.262\n",
      "Epoch 127: train_loss = 0.041, val_error_rate = 0.167, time/epoch = 75.911\n",
      "Epoch 128: train_loss = 0.035, val_error_rate = 0.158, time/epoch = 76.075\n",
      "Epoch 129: train_loss = 0.083, val_error_rate = 0.219, time/epoch = 76.483\n",
      "Epoch 130: train_loss = 0.024, val_error_rate = 0.177, time/epoch = 76.759\n",
      "Epoch 131: train_loss = 0.053, val_error_rate = 0.175, time/epoch = 74.918\n",
      "Epoch 132: train_loss = 0.054, val_error_rate = 0.172, time/epoch = 75.816\n",
      "Epoch 133: train_loss = 0.080, val_error_rate = 0.167, time/epoch = 75.935\n",
      "Epoch 134: train_loss = 0.078, val_error_rate = 0.174, time/epoch = 75.133\n",
      "Epoch 135: train_loss = 0.072, val_error_rate = 0.151, time/epoch = 74.628\n",
      "Epoch 136: train_loss = 0.061, val_error_rate = 0.150, time/epoch = 75.771\n",
      "Epoch 137: train_loss = 0.019, val_error_rate = 0.158, time/epoch = 75.805\n",
      "Epoch 138: train_loss = 0.043, val_error_rate = 0.152, time/epoch = 76.265\n",
      "Epoch 139: train_loss = 0.033, val_error_rate = 0.155, time/epoch = 75.848\n",
      "Epoch 140: train_loss = 0.030, val_error_rate = 0.151, time/epoch = 76.418\n",
      "Epoch 141: train_loss = 0.045, val_error_rate = 0.167, time/epoch = 75.339\n",
      "Epoch 142: train_loss = 0.023, val_error_rate = 0.174, time/epoch = 75.211\n",
      "Epoch 143: train_loss = 0.045, val_error_rate = 0.154, time/epoch = 75.230\n",
      "Epoch 144: train_loss = 0.034, val_error_rate = 0.141, time/epoch = 74.108\n",
      "Epoch 145: train_loss = 0.105, val_error_rate = 0.248, time/epoch = 76.254\n",
      "Epoch 146: train_loss = 0.093, val_error_rate = 0.162, time/epoch = 74.817\n",
      "Epoch 147: train_loss = 0.033, val_error_rate = 0.170, time/epoch = 76.452\n",
      "Epoch 148: train_loss = 0.050, val_error_rate = 0.144, time/epoch = 76.261\n",
      "Epoch 149: train_loss = 0.046, val_error_rate = 0.154, time/epoch = 75.982\n",
      "Epoch 150: train_loss = 0.023, val_error_rate = 0.163, time/epoch = 75.974\n",
      "Epoch 151: train_loss = 0.042, val_error_rate = 0.205, time/epoch = 75.531\n",
      "Epoch 152: train_loss = 0.015, val_error_rate = 0.176, time/epoch = 75.494\n",
      "Epoch 153: train_loss = 0.033, val_error_rate = 0.147, time/epoch = 74.366\n",
      "Epoch 154: train_loss = 0.040, val_error_rate = 0.169, time/epoch = 76.679\n",
      "Epoch 155: train_loss = 0.051, val_error_rate = 0.210, time/epoch = 76.041\n",
      "Epoch 156: train_loss = 0.022, val_error_rate = 0.162, time/epoch = 76.318\n",
      "Epoch 157: train_loss = 0.050, val_error_rate = 0.151, time/epoch = 74.646\n",
      "Epoch 158: train_loss = 0.043, val_error_rate = 0.147, time/epoch = 75.918\n",
      "Epoch 159: train_loss = 0.065, val_error_rate = 0.171, time/epoch = 73.558\n",
      "Epoch 160: train_loss = 0.036, val_error_rate = 0.144, time/epoch = 75.498\n",
      "Epoch 161: train_loss = 0.026, val_error_rate = 0.140, time/epoch = 76.456\n",
      "Epoch 162: train_loss = 0.056, val_error_rate = 0.148, time/epoch = 74.080\n",
      "Epoch 163: train_loss = 0.027, val_error_rate = 0.135, time/epoch = 75.518\n",
      "Epoch 164: train_loss = 0.047, val_error_rate = 0.145, time/epoch = 74.899\n",
      "Epoch 165: train_loss = 0.056, val_error_rate = 0.139, time/epoch = 75.973\n",
      "Epoch 166: train_loss = 0.062, val_error_rate = 0.154, time/epoch = 74.796\n",
      "Epoch 167: train_loss = 0.069, val_error_rate = 0.141, time/epoch = 75.260\n",
      "Epoch 168: train_loss = 0.012, val_error_rate = 0.140, time/epoch = 76.709\n",
      "Epoch 169: train_loss = 0.020, val_error_rate = 0.138, time/epoch = 76.309\n",
      "Epoch 170: train_loss = 0.032, val_error_rate = 0.140, time/epoch = 77.131\n",
      "Epoch 171: train_loss = 0.021, val_error_rate = 0.146, time/epoch = 75.499\n",
      "Epoch 172: train_loss = 0.051, val_error_rate = 0.136, time/epoch = 77.374\n",
      "Epoch 173: train_loss = 0.024, val_error_rate = 0.133, time/epoch = 74.752\n",
      "Epoch 174: train_loss = 0.035, val_error_rate = 0.128, time/epoch = 75.674\n",
      "Epoch 175: train_loss = 0.043, val_error_rate = 0.186, time/epoch = 74.910\n",
      "Epoch 176: train_loss = 0.038, val_error_rate = 0.165, time/epoch = 75.328\n",
      "Epoch 177: train_loss = 0.050, val_error_rate = 0.219, time/epoch = 75.546\n",
      "Epoch 178: train_loss = 0.072, val_error_rate = 0.168, time/epoch = 75.824\n",
      "Epoch 179: train_loss = 0.040, val_error_rate = 0.156, time/epoch = 75.771\n",
      "Epoch 180: train_loss = 0.027, val_error_rate = 0.148, time/epoch = 74.939\n",
      "Epoch 181: train_loss = 0.024, val_error_rate = 0.140, time/epoch = 74.155\n",
      "Epoch 182: train_loss = 0.037, val_error_rate = 0.135, time/epoch = 75.812\n",
      "Epoch 183: train_loss = 0.031, val_error_rate = 0.126, time/epoch = 75.305\n",
      "Epoch 184: train_loss = 0.024, val_error_rate = 0.136, time/epoch = 76.243\n",
      "Epoch 185: train_loss = 0.121, val_error_rate = 0.151, time/epoch = 75.665\n",
      "Epoch 186: train_loss = 0.052, val_error_rate = 0.156, time/epoch = 76.770\n",
      "Epoch 187: train_loss = 0.056, val_error_rate = 0.141, time/epoch = 74.732\n",
      "Epoch 188: train_loss = 0.015, val_error_rate = 0.136, time/epoch = 76.151\n",
      "Epoch 189: train_loss = 0.013, val_error_rate = 0.134, time/epoch = 76.243\n",
      "Epoch 190: train_loss = 0.031, val_error_rate = 0.145, time/epoch = 74.920\n",
      "Epoch 191: train_loss = 0.035, val_error_rate = 0.156, time/epoch = 76.107\n",
      "Epoch 192: train_loss = 0.025, val_error_rate = 0.132, time/epoch = 74.790\n",
      "Epoch 193: train_loss = 0.037, val_error_rate = 0.137, time/epoch = 74.851\n",
      "Epoch 194: train_loss = 0.035, val_error_rate = 0.145, time/epoch = 75.762\n",
      "Epoch 195: train_loss = 0.079, val_error_rate = 0.155, time/epoch = 75.203\n",
      "Epoch 196: train_loss = 0.046, val_error_rate = 0.146, time/epoch = 75.571\n",
      "Epoch 197: train_loss = 0.067, val_error_rate = 0.136, time/epoch = 74.686\n",
      "Epoch 198: train_loss = 0.029, val_error_rate = 0.152, time/epoch = 74.552\n",
      "Epoch 199: train_loss = 0.027, val_error_rate = 0.140, time/epoch = 76.672\n",
      "Epoch 200: train_loss = 0.017, val_error_rate = 0.132, time/epoch = 74.709\n",
      "Epoch 201: train_loss = 0.030, val_error_rate = 0.159, time/epoch = 76.066\n",
      "Epoch 202: train_loss = 0.072, val_error_rate = 0.133, time/epoch = 76.088\n",
      "Epoch 203: train_loss = 0.056, val_error_rate = 0.139, time/epoch = 75.399\n",
      "Epoch 204: train_loss = 0.023, val_error_rate = 0.152, time/epoch = 76.294\n",
      "Epoch 205: train_loss = 0.022, val_error_rate = 0.132, time/epoch = 75.361\n",
      "Epoch 206: train_loss = 0.048, val_error_rate = 0.151, time/epoch = 74.594\n",
      "Epoch 207: train_loss = 0.036, val_error_rate = 0.164, time/epoch = 75.584\n",
      "Epoch 208: train_loss = 0.109, val_error_rate = 0.173, time/epoch = 76.820\n",
      "Epoch 209: train_loss = 0.039, val_error_rate = 0.146, time/epoch = 74.633\n",
      "Epoch 210: train_loss = 0.027, val_error_rate = 0.143, time/epoch = 76.054\n",
      "Epoch 211: train_loss = 0.040, val_error_rate = 0.120, time/epoch = 75.527\n",
      "Epoch 212: train_loss = 0.044, val_error_rate = 0.126, time/epoch = 75.717\n",
      "Epoch 213: train_loss = 0.039, val_error_rate = 0.121, time/epoch = 74.665\n",
      "Epoch 214: train_loss = 0.059, val_error_rate = 0.113, time/epoch = 75.133\n",
      "Epoch 215: train_loss = 0.027, val_error_rate = 0.119, time/epoch = 74.423\n",
      "Epoch 216: train_loss = 0.022, val_error_rate = 0.116, time/epoch = 74.463\n",
      "Epoch 217: train_loss = 0.048, val_error_rate = 0.139, time/epoch = 75.558\n",
      "Epoch 218: train_loss = 0.017, val_error_rate = 0.133, time/epoch = 75.135\n",
      "Epoch 219: train_loss = 0.023, val_error_rate = 0.123, time/epoch = 75.588\n",
      "Epoch 220: train_loss = 0.035, val_error_rate = 0.118, time/epoch = 75.974\n",
      "Epoch 221: train_loss = 0.027, val_error_rate = 0.132, time/epoch = 76.448\n",
      "Epoch 222: train_loss = 0.012, val_error_rate = 0.120, time/epoch = 75.311\n",
      "Epoch 223: train_loss = 0.030, val_error_rate = 0.122, time/epoch = 75.857\n",
      "Epoch 224: train_loss = 0.081, val_error_rate = 0.144, time/epoch = 75.072\n",
      "Epoch 225: train_loss = 0.013, val_error_rate = 0.129, time/epoch = 75.282\n",
      "Epoch 226: train_loss = 0.063, val_error_rate = 0.132, time/epoch = 75.937\n",
      "Epoch 227: train_loss = 0.015, val_error_rate = 0.131, time/epoch = 75.852\n",
      "Epoch 228: train_loss = 0.033, val_error_rate = 0.115, time/epoch = 74.597\n",
      "Epoch 229: train_loss = 0.025, val_error_rate = 0.112, time/epoch = 76.706\n",
      "Epoch 230: train_loss = 0.036, val_error_rate = 0.122, time/epoch = 76.551\n",
      "Epoch 231: train_loss = 0.020, val_error_rate = 0.116, time/epoch = 75.313\n",
      "Epoch 232: train_loss = 0.020, val_error_rate = 0.115, time/epoch = 75.943\n",
      "Epoch 233: train_loss = 0.110, val_error_rate = 0.115, time/epoch = 74.075\n",
      "Epoch 234: train_loss = 0.011, val_error_rate = 0.106, time/epoch = 76.122\n",
      "Epoch 235: train_loss = 0.020, val_error_rate = 0.102, time/epoch = 75.524\n",
      "Epoch 236: train_loss = 0.036, val_error_rate = 0.098, time/epoch = 76.209\n",
      "Epoch 237: train_loss = 0.016, val_error_rate = 0.083, time/epoch = 75.152\n",
      "Epoch 238: train_loss = 0.012, val_error_rate = 0.098, time/epoch = 76.027\n",
      "Epoch 239: train_loss = 0.016, val_error_rate = 0.099, time/epoch = 76.117\n",
      "Epoch 240: train_loss = 0.061, val_error_rate = 0.131, time/epoch = 76.051\n",
      "Epoch 241: train_loss = 0.025, val_error_rate = 0.110, time/epoch = 75.903\n",
      "Epoch 242: train_loss = 0.016, val_error_rate = 0.112, time/epoch = 76.350\n",
      "Epoch 243: train_loss = 0.053, val_error_rate = 0.099, time/epoch = 76.594\n",
      "Epoch 244: train_loss = 0.016, val_error_rate = 0.106, time/epoch = 75.681\n",
      "Epoch 245: train_loss = 0.033, val_error_rate = 0.102, time/epoch = 75.554\n",
      "Epoch 246: train_loss = 0.027, val_error_rate = 0.092, time/epoch = 74.885\n",
      "Epoch 247: train_loss = 0.023, val_error_rate = 0.105, time/epoch = 75.544\n",
      "Epoch 248: train_loss = 0.018, val_error_rate = 0.080, time/epoch = 75.704\n",
      "Epoch 249: train_loss = 0.010, val_error_rate = 0.108, time/epoch = 75.522\n",
      "Epoch 250: train_loss = 0.032, val_error_rate = 0.114, time/epoch = 74.838\n",
      "Epoch 251: train_loss = 0.026, val_error_rate = 0.093, time/epoch = 76.614\n",
      "Epoch 252: train_loss = 0.022, val_error_rate = 0.082, time/epoch = 75.880\n",
      "Epoch 253: train_loss = 0.024, val_error_rate = 0.081, time/epoch = 74.807\n",
      "Epoch 254: train_loss = 0.014, val_error_rate = 0.081, time/epoch = 74.910\n",
      "Epoch 255: train_loss = 0.031, val_error_rate = 0.079, time/epoch = 76.200\n",
      "Epoch 256: train_loss = 0.006, val_error_rate = 0.074, time/epoch = 77.049\n",
      "Epoch 257: train_loss = 0.008, val_error_rate = 0.077, time/epoch = 74.954\n",
      "Epoch 258: train_loss = 0.037, val_error_rate = 0.083, time/epoch = 75.673\n",
      "Epoch 259: train_loss = 0.010, val_error_rate = 0.105, time/epoch = 76.522\n",
      "Epoch 260: train_loss = 0.012, val_error_rate = 0.087, time/epoch = 75.182\n",
      "Epoch 261: train_loss = 0.008, val_error_rate = 0.084, time/epoch = 74.690\n",
      "Epoch 262: train_loss = 0.013, val_error_rate = 0.087, time/epoch = 74.748\n",
      "Epoch 263: train_loss = 0.012, val_error_rate = 0.083, time/epoch = 75.929\n",
      "Epoch 264: train_loss = 0.021, val_error_rate = 0.077, time/epoch = 76.074\n",
      "Epoch 265: train_loss = 0.012, val_error_rate = 0.079, time/epoch = 72.942\n",
      "Epoch 266: train_loss = 0.011, val_error_rate = 0.079, time/epoch = 75.753\n",
      "Epoch 267: train_loss = 0.027, val_error_rate = 0.094, time/epoch = 73.516\n",
      "Epoch 268: train_loss = 0.015, val_error_rate = 0.091, time/epoch = 74.944\n",
      "Epoch 269: train_loss = 0.030, val_error_rate = 0.095, time/epoch = 75.293\n",
      "Epoch 270: train_loss = 0.067, val_error_rate = 0.094, time/epoch = 75.903\n",
      "Epoch 271: train_loss = 0.047, val_error_rate = 0.091, time/epoch = 75.643\n",
      "Epoch 272: train_loss = 0.010, val_error_rate = 0.088, time/epoch = 74.657\n",
      "Epoch 273: train_loss = 0.069, val_error_rate = 0.104, time/epoch = 76.297\n",
      "Epoch 274: train_loss = 0.040, val_error_rate = 0.074, time/epoch = 75.711\n",
      "Epoch 275: train_loss = 0.011, val_error_rate = 0.083, time/epoch = 75.496\n",
      "Epoch 276: train_loss = 0.006, val_error_rate = 0.065, time/epoch = 74.413\n",
      "Epoch 277: train_loss = 0.028, val_error_rate = 0.096, time/epoch = 74.996\n",
      "Epoch 278: train_loss = 0.022, val_error_rate = 0.086, time/epoch = 75.267\n",
      "Epoch 279: train_loss = 0.010, val_error_rate = 0.076, time/epoch = 74.834\n",
      "Epoch 280: train_loss = 0.008, val_error_rate = 0.084, time/epoch = 76.356\n",
      "Epoch 281: train_loss = 0.031, val_error_rate = 0.083, time/epoch = 76.146\n",
      "Epoch 282: train_loss = 0.048, val_error_rate = 0.087, time/epoch = 75.696\n",
      "Epoch 283: train_loss = 0.015, val_error_rate = 0.098, time/epoch = 73.564\n",
      "Epoch 284: train_loss = 0.004, val_error_rate = 0.094, time/epoch = 74.744\n",
      "Epoch 285: train_loss = 0.013, val_error_rate = 0.082, time/epoch = 75.432\n",
      "Epoch 286: train_loss = 0.055, val_error_rate = 0.098, time/epoch = 75.939\n",
      "Epoch 287: train_loss = 0.015, val_error_rate = 0.084, time/epoch = 74.837\n",
      "Epoch 288: train_loss = 0.013, val_error_rate = 0.118, time/epoch = 75.356\n",
      "Epoch 289: train_loss = 0.008, val_error_rate = 0.083, time/epoch = 75.669\n",
      "Epoch 290: train_loss = 0.010, val_error_rate = 0.083, time/epoch = 74.670\n",
      "Epoch 291: train_loss = 0.008, val_error_rate = 0.082, time/epoch = 75.333\n",
      "Epoch 292: train_loss = 0.045, val_error_rate = 0.103, time/epoch = 75.741\n",
      "Epoch 293: train_loss = 0.021, val_error_rate = 0.080, time/epoch = 74.832\n",
      "Epoch 294: train_loss = 0.027, val_error_rate = 0.086, time/epoch = 74.767\n",
      "Epoch 295: train_loss = 0.053, val_error_rate = 0.082, time/epoch = 74.813\n",
      "Epoch 296: train_loss = 0.036, val_error_rate = 0.083, time/epoch = 75.254\n",
      "Epoch 297: train_loss = 0.032, val_error_rate = 0.083, time/epoch = 76.466\n",
      "Epoch 298: train_loss = 0.030, val_error_rate = 0.075, time/epoch = 75.935\n",
      "Epoch 299: train_loss = 0.018, val_error_rate = 0.071, time/epoch = 75.093\n",
      "Epoch 300: train_loss = 0.005, val_error_rate = 0.068, time/epoch = 76.894\n",
      "Epoch 301: train_loss = 0.026, val_error_rate = 0.068, time/epoch = 76.407\n",
      "Epoch 302: train_loss = 0.047, val_error_rate = 0.062, time/epoch = 76.897\n",
      "Epoch 303: train_loss = 0.020, val_error_rate = 0.089, time/epoch = 75.581\n",
      "Epoch 304: train_loss = 0.021, val_error_rate = 0.071, time/epoch = 74.803\n",
      "Epoch 305: train_loss = 0.012, val_error_rate = 0.073, time/epoch = 75.832\n",
      "Epoch 306: train_loss = 0.006, val_error_rate = 0.085, time/epoch = 76.051\n",
      "Epoch 307: train_loss = 0.014, val_error_rate = 0.072, time/epoch = 77.106\n",
      "Epoch 308: train_loss = 0.022, val_error_rate = 0.069, time/epoch = 74.749\n",
      "Epoch 309: train_loss = 0.100, val_error_rate = 0.099, time/epoch = 75.569\n",
      "Epoch 310: train_loss = 0.016, val_error_rate = 0.080, time/epoch = 77.030\n",
      "Epoch 311: train_loss = 0.019, val_error_rate = 0.090, time/epoch = 80.039\n",
      "Epoch 312: train_loss = 0.027, val_error_rate = 0.097, time/epoch = 84.503\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-fa068ce799bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                         \u001b[0mtesting_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtesting_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                         batches_per_epoch=128)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/erik/proj/pycon/seq2seq/model.py\u001b[0m in \u001b[0;36mfit_curr\u001b[0;34m(self, data_generator, testing_model, num_epochs, batches_per_epoch, lr_decay, num_val_batches)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/erik/proj/pycon/seq2seq/model.py\u001b[0m in \u001b[0;36m_fit_batch\u001b[0;34m(self, input_values, targets)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0minput_feed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/erik/anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \"\"\"\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/erik/anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 511\u001b[0;31m                            feed_dict_string)\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/erik/anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 564\u001b[0;31m                            target_list)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/erik/anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    569\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/erik/anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_model.fit_curr(program_generator, \n",
    "                        testing_model=testing_model, \n",
    "                        num_epochs=20000, \n",
    "                        batches_per_epoch=128)\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f=18\n",
      "if f>8:\n",
      "  f-=54\n",
      "print(f)\n",
      "-----\n",
      "Targ: -36\n",
      "Pred: -46\n",
      "(100, 10, 48) (100, 11, 48)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "test_generator = ProgramGenerator(batch_size=batch_size, num_len=2, program_length=1)\n",
    "\n",
    "x, y = test_generator.next_batch()\n",
    "\n",
    "input_strings = decode_output_sequences(x, symbols=SYMBOLS)\n",
    "target_strings = decode_output_sequences(y, symbols=SYMBOLS)\n",
    "\n",
    "model_output = testing_model.predict(x)\n",
    "\n",
    "pred_strings = decode_output_sequences(model_output, symbols=SYMBOLS)\n",
    "\n",
    "def view_prediction(i):\n",
    "    print(input_strings[i].strip('_').strip('G'))\n",
    "    print(\"-----\")\n",
    "    print(\"Targ:\", target_strings[i].strip('_'))\n",
    "    print(\"Pred:\", pred_strings[i].strip('_'))\n",
    "    print(y.shape, model_output.shape)\n",
    "a = interact(view_prediction, i=(0, batch_size - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09666666666666668"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%prun\n",
    "#from model import validate_model\n",
    "testing_model.validate([test_generator.next_batch() for _ in range(30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
